
@misc{phoible2013,
  address = {Munich},
  title = {{{PHOIBLE}}: {{Phonetics Information Base}} and {{Lexicon Online}}},
  url = {http://phoible.org},
  publisher = {{Max Planck Digital Library}},
  collaborator = {Moran, Steven and McCloy, Daniel R. and Wright, Richard A.},
  year = {2013}
}

@article{LahiriReetz2010,
  title = {Distinctive Features: {{Phonological}} Underspecification in Representation and Processing},
  volume = {38},
  issn = {0095-4470},
  doi = {10.1016/j.wocn.2010.01.002},
  abstract = {Phonological variation of any sort (determined by speech styles, phrasing, or morphophonological rules) affecting the shapes of words and morphemes are a matter of concern for theories of speech perception and language comprehension. To come to grips with parsing the speech stream, accessing the lexicon and ultimately recognizing words, both representational as well as processing issues must be considered. The central questions in the research presented here are: What is represented in the mental lexicon? How is it represented? How is the speech signal parsed and information mapped onto the mental lexicon? In this paper we will address four issues within the framework of our Featurally Underspecified Lexicon model (FUL): (a) our assumptions concerning distinctive feature organization defined by phonological, perceptual and acoustic constraints; (b) specification of features in the mental lexicon (based on universal and language specific requirements); (c) extracting distinctive features from the signal; (d) mapping features from the signal to the lexicon. We claim that phonological features are extracted from the variable acoustic signal based on broad acoustic properties. A three-way matching algorithm maps these features onto highly abstract phonological mental representations. We provide evidence from synchronic phonological analyses, language change, psycholinguistic and neurolinguistic data.},
  number = {1},
  url = {http://www.sciencedirect.com/science/article/pii/S0095447010000033},
  journal = {Journal of Phonetics},
  author = {Lahiri, Aditi and Reetz, Henning},
  month = jan,
  year = {2010},
  pages = {44--59},
  file = {/home/drmccloy/Bibliography/storage/J3A5QPPQ/Lahiri&Reetz2010_Underspecification.pdf},
  note = {Special issue: Phonetic Bases of Distinctive Features}
}

@article{McClellandElman1986,
  title = {The {{TRACE}} Model of Speech Perception},
  volume = {18},
  issn = {00100285},
  doi = {10.1016/0010-0285(86)90015-0},
  number = {1},
  urldate = {2013-05-09},
  url = {http://linkinghub.elsevier.com/retrieve/pii/0010028586900150},
  journal = {Cognitive Psychology},
  author = {McClelland, James L. and Elman, Jeffrey L.},
  month = jan,
  year = {1986},
  pages = {1--86},
  file = {/home/drmccloy/Bibliography/storage/GP25WNFC/McClelland&Elman1986_TraceModelOfSpeechPerc.pdf}
}

@article{Chao1934,
  title = {The Non-Uniqueness of Phonemic Solutions of Phonetic Systems},
  volume = {4},
  number = {4},
  journal = {Bulletin of the Institute of History and Philology, Academia Sinica},
  author = {Chao, Yuen Ren},
  year = {1934}
}

@book{Hayes2009,
  address = {Oxford, UK},
  title = {Introductory Phonology},
  isbn = {978-1-4051-8411-3},
  language = {English},
  publisher = {{Wiley-Blackwell}},
  author = {Hayes, Bruce P.},
  year = {2009}
}

@article{Clements1985,
  title = {The Geometry of Phonological Features},
  volume = {2},
  issn = {0265-8062},
  url = {http://www.jstor.org/stable/4419958},
  journal = {Phonology Yearbook},
  author = {Clements, G. N.},
  year = {1985},
  pages = {225--252},
  file = {/home/drmccloy/Bibliography/storage/G3D8IT2J/clements1985_featureGeometry.pdf}
}

@article{MillerNicely1955,
  title = {An Analysis of Perceptual Confusions among Some {{English}} Consonants},
  volume = {27},
  issn = {00014966},
  doi = {10.1121/1.1907526},
  number = {2},
  urldate = {2013-05-09},
  url = {http://link.aip.org/link/JASMAN/v27/i2/p338/s1\&Agg=doi},
  journal = {The Journal of the Acoustical Society of America},
  author = {Miller, George A. and Nicely, Patricia E.},
  year = {1955},
  pages = {338--352},
  file = {/home/drmccloy/Bibliography/storage/4M8P4C4W/MillerNicely1955_EngConsonantConfusions.pdf;/home/drmccloy/Bibliography/storage/8L3HNFQR/MillerNicely1955_Erratum.pdf}
}

@book{Stevens2000,
  address = {Cambridge, MA},
  title = {Acoustic Phonetics},
  isbn = {978-0-262-19404-4},
  publisher = {{MIT Press}},
  author = {Stevens, Kenneth Noble},
  year = {2000},
  file = {/home/drmccloy/Bibliography/storage/792Q6A6E/Stevens2000_AcousticPhonetics.pdf}
}

@incollection{ClementsHume1995,
  title = {The Internal Organization of Speech Sounds},
  booktitle = {The Handbook of Phonological Theory},
  publisher = {{Blackwell}},
  author = {Clements, G. N. and Hume, Elizabeth V.},
  editor = {Goldsmith, John},
  year = {1995},
  pages = {245--306}
}

@article{EulitzLahiri2004,
  title = {Neurobiological Evidence for Abstract Phonological Representations in the Mental Lexicon during Speech Recognition},
  volume = {16},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/089892904323057308},
  number = {4},
  urldate = {2013-02-01},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/089892904323057308},
  journal = {Journal of Cognitive Neuroscience},
  author = {Eulitz, Carsten and Lahiri, Aditi},
  month = may,
  year = {2004},
  pages = {577--583},
  file = {/home/drmccloy/Bibliography/storage/F8WUCFTC/Eulitz&Lahiri2004_NeuroEvidenceForPhonology.pdf},
  pmid = {15185677}
}

@incollection{Maeda1990,
  series = {NATO ASI Series D: Behavioural and Social Sciences},
  title = {Compensatory Articulation during Speech: {{Evidence}} from the Analysis and Synthesis of Vocal-Tract Shapes Using an Articulatory Model},
  isbn = {978-94-009-2037-8},
  number = {55},
  url = {http://link.springer.com/book/10.1007/978-94-009-2037-8},
  booktitle = {Speech Production and Speech Modeling},
  publisher = {{Springer Netherlands}},
  author = {Maeda, Shinji},
  editor = {Hardcastle, William J. and Marchal, Alain},
  year = {1990},
  pages = {131--149},
  file = {/home/drmccloy/Bibliography/storage/66SJNK98/Maeda1990_CompensatoryArticulation.pdf},
  doi = {10.1007/978-94-009-2037-8}
}

@article{SSP,
  title = {Signal-Space Projection Method for Separating {{MEG}} or {{EEG}} into Components},
  volume = {35},
  issn = {0140-0118, 1741-0444},
  doi = {10.1007/BF02534144},
  language = {en},
  number = {2},
  urldate = {2014-03-21},
  url = {http://link.springer.com/10.1007/BF02534144},
  journal = {Medical \& Biological Engineering \& Computing},
  author = {Uusitalo, M. A. and Ilmoniemi, R. J.},
  month = mar,
  year = {1997},
  pages = {135--140},
  file = {/home/drmccloy/Bibliography/storage/CBTQCDZH/UusitaloIlmoniemi1997_SSP.pdf},
  pmid = {9136207}
}

@article{LottoEtAl2009,
  title = {Reflections on Mirror Neurons and Speech Perception},
  volume = {13},
  issn = {13646613},
  doi = {10.1016/j.tics.2008.11.008},
  language = {en},
  number = {3},
  urldate = {2014-03-19},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661309000205},
  journal = {Trends in Cognitive Sciences},
  author = {Lotto, Andrew J. and Hickok, Gregory S. and Holt, Lori L.},
  month = mar,
  year = {2009},
  pages = {110--114},
  file = {/home/drmccloy/Bibliography/storage/T2WH4MS7/LottoEtAl2009_MirrorNeuronsAndMotorTheory.pdf}
}

@article{VadenEtAl2010,
  title = {Phonological Repetition-Suppression in Bilateral Superior Temporal Sulci},
  volume = {49},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2009.07.063},
  language = {en},
  number = {1},
  urldate = {2014-03-21},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811909008519},
  journal = {NeuroImage},
  author = {Vaden, Kenneth I. and Muftuler, L. Tugan and Hickok, Gregory},
  month = jan,
  year = {2010},
  pages = {1018--1023},
  file = {/home/drmccloy/Bibliography/storage/SEFMNJSK/VadenetAl2010_PhonologicalRepetitionSuppressionInSTS.pdf},
  pmid = {19651222},
  pmcid = {PMC2764799}
}

@book{ChomskyHalleSPE,
  address = {Cambridge, MA},
  title = {The Sound Pattern of {{English}}},
  isbn = {978-90-00-07517-1},
  publisher = {{MIT Press}},
  author = {Chomsky, Noam and Halle, Morris},
  year = {[1991] 1968},
  file = {/home/drmccloy/Bibliography/storage/NEGN2QC3/ChomskyHalle1968_SPE.pdf}
}

@article{mnepython,
  title = {{{MEG}} and {{EEG}} Data Analysis with {{MNE}}-{{Python}}},
  volume = {7},
  issn = {1662453X},
  doi = {10.3389/fnins.2013.00267},
  number = {267},
  urldate = {2015-10-05},
  url = {http://journal.frontiersin.org/article/10.3389/fnins.2013.00267/abstract},
  journal = {Frontiers in Neuroscience},
  author = {Gramfort, Alexandre and Luessi, Martin and Larson, Eric D. and Engemann, Denis A. and Strohmeier, Daniel and Brodbeck, Christian and Goj, Roman and Jas, Mainak and Brooks, Teon and Parkkonen, Lauri and H{\"a}m{\"a}l{\"a}inen, Matti S.},
  year = {2013},
  pages = {1--13},
  file = {/home/drmccloy/Bibliography/storage/VQ3XUFX4/GramfortEtAl2013_mnePython.pdf}
}

@article{MesgaraniEtAl2014,
  title = {Phonetic Feature Encoding in Human Superior Temporal Gyrus},
  volume = {343},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1245994},
  language = {en},
  number = {6174},
  urldate = {2015-11-15},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1245994},
  journal = {Science},
  author = {Mesgarani, Nima and Cheung, Connie and Johnson, Keith and Chang, Edward F.},
  month = feb,
  year = {2014},
  pages = {1006--1010},
  file = {/home/drmccloy/Bibliography/storage/D98AKC4A/MesgaraniEtAl2014_Supplement.pdf;/home/drmccloy/Bibliography/storage/RN6CH3VS/MesgaraniEtAl2014_PhonemeHumanECOG.pdf}
}

@article{SarelaValpola2005,
  title = {Denoising Source Separation},
  volume = {6},
  issn = {1533-7928},
  url = {http://www.jmlr.org/papers/v6/sarela05a.html},
  journal = {Journal of Machine Learning Research},
  author = {S{\"a}rel{\"a}, Jaakko and Valpola, Harri},
  year = {2005},
  pages = {233--272},
  file = {/home/drmccloy/Bibliography/storage/9EC99VUG/SarelaValpola2005_DSS.pdf}
}

@article{deCheveigneSimon2008,
  title = {Denoising Based on Spatial Filtering},
  volume = {171},
  issn = {01650270},
  doi = {10.1016/j.jneumeth.2008.03.015},
  language = {en},
  number = {2},
  urldate = {2016-04-12},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0165027008002008},
  journal = {Journal of Neuroscience Methods},
  author = {{de Cheveign{\'e}}, Alain and Simon, Jonathan Z.},
  month = jun,
  year = {2008},
  pages = {331--339},
  file = {/home/drmccloy/Bibliography/storage/GPFUIVZX/deCheveigneSimon2008_DSS.pdf}
}

@book{JakobsonFantHalle1952,
  address = {Cambridge},
  title = {Preliminaries to Speech Analysis: {{The}} Distinctive Features and Their Correlates},
  shorttitle = {Preliminaries to Speech Analysis},
  publisher = {{MIT Press}},
  author = {Jakobson, Roman and Fant, C. Gunnar M. and Halle, Morris},
  year = {1952}
}

@article{MielkeHume2006,
  address = {Oxford},
  edition = {2},
  title = {Distinctive Features},
  isbn = {978-0-08-044854-1},
  language = {en},
  urldate = {2016-07-07},
  url = {http://linkinghub.elsevier.com/retrieve/pii/B0080448542000365},
  journal = {Encyclopedia of Language \& Linguistics},
  publisher = {{Elsevier}},
  author = {Mielke, Jeff and Hume, Elizabeth V.},
  editor = {Brown, Keith},
  year = {2006},
  pages = {723--731},
  file = {/home/drmccloy/Bibliography/storage/WNC5WWMV/MielkeHume2006_Distinctive_Features.pdf}
}

@incollection{Best1995,
  address = {Baltimore},
  title = {A Direct Realist View of Cross-Language Speech Perception},
  booktitle = {Speech Perception and Linguistic Experience: {{Issues}} in Cross-Language Research},
  publisher = {{York Press}},
  author = {Best, Catherine T.},
  editor = {Strange, Winifred},
  year = {1995},
  pages = {171--204}
}

@article{LibermanEtAl1967,
  title = {Perception of the Speech Code},
  volume = {74},
  issn = {0033-295X},
  doi = {10.1037/h0020279},
  language = {en},
  number = {6},
  urldate = {2016-07-07},
  url = {http://content.apa.org/journals/rev/74/6/431},
  journal = {Psychological Review},
  author = {Liberman, A. M. and Cooper, F. S. and Shankweiler, D. P. and Studdert-Kennedy, M.},
  year = {1967},
  pages = {431--461},
  file = {/home/drmccloy/Bibliography/storage/JQAWNESQ/LibermanEtAl1967_Perception_of_the_speech_code.pdf}
}

@article{RobertsEtAl2014,
  title = {Asymmetric Processing of Durational Differences - Electrophysiological Investigations in {{Bengali}}},
  volume = {58},
  issn = {1873-3514},
  doi = {10.1016/j.neuropsychologia.2014.03.015},
  abstract = {Duration is used contrastively in many languages to distinguish word meaning (e.g. in Bengali, [pata] 'leaf' vs. [pat:a] 'whereabouts'). While there is a large body of research on other contrasts in speech perception (e.g. vowel contrasts and consonantal place features), little work has been done on how durational information is used in speech processing. In non-linguistic studies of low-level processing, such as visual and non-linguistic acoustic pop-out tasks, an asymmetry is found where additional information is more readily detected than missing information. In this study, event-related potentials were recorded during two cross-modal auditory-visual semantic priming studies, where nonword mispronunciations of spoken prime words were created by changing the duration of a medial consonant (real word [dana] 'seed'$>$nonword [dan:a]). N400 amplitudes showed an opposite asymmetric pattern of results, where increases in consonantal duration were tolerated and led to priming of the visual target, but decreases in consonantal duration were not accepted. This asymmetrical pattern of acceptability is attributed to the fact that a longer consonant includes all essential information for the recognition of the original word with a short medial consonant (a possible default category) and any additional information can be ignored. However, when a consonant is shortened, it lacks the required durational information to activate the word with the original long consonant.},
  language = {eng},
  journal = {Neuropsychologia},
  author = {Roberts, Adam C. and Kotzor, Sandra and Wetterlin, Allison and Lahiri, Aditi},
  month = may,
  year = {2014},
  pages = {88--98},
  file = {/home/drmccloy/Bibliography/storage/JE6BAM3K/RobertsEtAl2014_Asymmetric_processing_of_durational_differences_-.pdf},
  pmid = {24726333}
}

@article{MarkiewiczBohland2016,
  title = {Mapping the Cortical Representation of Speech Sounds in a Syllable Repetition Task},
  volume = {141},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2016.07.023},
  language = {en},
  urldate = {2017-04-20},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811916303317},
  journal = {NeuroImage},
  author = {Markiewicz, Christopher J. and Bohland, Jason W.},
  month = nov,
  year = {2016},
  pages = {174--190},
  file = {/home/drmccloy/Bibliography/storage/7DDZT2XG/MarkiewiczBohland2016_Mapping_the_cortical_representation_of_speech_sounds_in_a.pdf}
}

@article{KriegeskorteEtAl2008,
  title = {Representational Similarity Analysis \textendash{} Connecting the Branches of Systems Neuroscience},
  volume = {2},
  issn = {1662-5137},
  doi = {10.3389/neuro.06.004.2008},
  abstract = {A FUNDAMENTAL CHALLENGE FOR SYSTEMS NEUROSCIENCE IS TO QUANTITATIVELY RELATE ITS THREE MAJOR BRANCHES OF RESEARCH: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging (fMRI). Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., fMRI and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices (RDMs), which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis (RSA), in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing RDMs. We demonstrate RSA by relating representations of visual objects as measured with fMRI in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities. The RDMs are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of RSA, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
  url = {http://journal.frontiersin.org/article/10.3389/neuro.06.004.2008/abstract},
  journal = {Frontiers in Systems Neuroscience},
  author = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter},
  year = {2008},
  pages = {4},
  file = {/home/drmccloy/Bibliography/storage/ITAH59TA/KriegeskorteEtAl2008_Representational_similarity_analysis_–_connecting_the_branches_of_systems.pdf},
  pmid = {19104670},
  pmcid = {PMC2605405}
}

@article{ChangEtAl2010,
  title = {Categorical Speech Representation in Human Superior Temporal Gyrus},
  volume = {13},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.2641},
  number = {11},
  urldate = {2017-07-10},
  url = {http://www.nature.com/doifinder/10.1038/nn.2641},
  journal = {Nature Neuroscience},
  author = {Chang, Edward F and Rieger, Jochem W and Johnson, Keith and Berger, Mitchel S and Barbaro, Nicholas M and Knight, Robert T},
  month = nov,
  year = {2010},
  pages = {1428--1432},
  file = {/home/drmccloy/Bibliography/storage/NPFY33IT/ChangEtAl2010_Supplement.pdf;/home/drmccloy/Bibliography/storage/X6QX4E2P/ChangEtAl2010_Categorical_speech_representation_in_human_superior_temporal_gyrus.pdf}
}

@article{BarJosephEtAl2001,
  title = {Fast Optimal Leaf Ordering for Hierarchical Clustering},
  volume = {17},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/17.suppl_1.S22},
  abstract = {We present the first practical algorithm for the optimal linear leaf ordering of trees that are generated by hierarchical clustering. Hierarchical clustering has been extensively used to analyze gene expression data, and we show how optimal leaf ordering can reveal biological structure that is not observed with an existing heuristic ordering method. For a tree with n leaves, there are 2(n-1) linear orderings consistent with the structure of the tree. Our optimal leaf ordering algorithm runs in time O(n(4)), and we present further improvements that make the running time of our algorithm practical.},
  language = {en},
  number = {Suppl 1},
  urldate = {2017-09-05},
  url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/17.suppl_1.S22},
  journal = {Bioinformatics},
  author = {Bar-Joseph, Z. and Gifford, D. K. and Jaakkola, T. S.},
  month = jun,
  year = {2001},
  pages = {S22--S29},
  file = {/home/drmccloy/Bibliography/storage/DD7D687X/Bar-JosephEtAl2001_Fast_optimal_leaf_ordering_for_hierarchical_clustering.pdf},
  pmid = {11472989}
}

@article{BrowmanGoldstein1992,
  title = {Articulatory Phonology: {{An}} Overview},
  volume = {49},
  issn = {0031-8388},
  shorttitle = {Articulatory Phonology},
  doi = {10.1159/000261913},
  abstract = {An overview of the basic ideas of articulatory phonology is presented, along with selected examples of phonological patterning for which the approach seems to provide a particularly insightful account. In articulatory phonology, the basic units of phonological contrast are gestures, which are also abstract characterizations of articulatory events, each with an intrinsic time or duration. Utterances are modeled as organized patterns (constellations) of gestures, in which gestural units may overlap in time. The phonological structures defined in this way provide a set of articulatorily based natural classes. Moreover, the patterns of overlapping organization can be used to specify important aspects of the phonological structure of particular languages, and to account, in a coherent and general way, for a variety of different types of phonological variation. Such variation includes allophonic variation and fluent speech alternations, as well as 'coarticulation' and speech errors. Finally, it is suggested that the gestural approach clarifies our understanding of phonological development, by positing that prelinguistic units of action are harnessed into (gestural) phonological structures through differentiation and coordination.},
  language = {en},
  number = {3-4},
  urldate = {2017-10-16},
  url = {http://www.karger.com/doi/10.1159/000261913},
  journal = {Phonetica},
  author = {Browman, Catherine P. and Goldstein, Louis},
  year = {1992},
  pages = {155--180},
  file = {/home/drmccloy/Bibliography/storage/IJJDFMRK/Browman_Goldstein_1992_Articulatory_phonology.pdf},
  pmid = {1488456}
}

@article{BrowmanGoldstein1989,
  title = {Articulatory Gestures as Phonological Units},
  volume = {6},
  issn = {0952-6757, 1469-8188},
  doi = {10.1017/S0952675700001019},
  language = {en},
  number = {02},
  urldate = {2017-10-16},
  url = {http://www.journals.cambridge.org/abstract_S0952675700001019},
  journal = {Phonology},
  author = {Browman, Catherine P. and Goldstein, Louis},
  month = aug,
  year = {1989},
  pages = {201--251},
  file = {/home/drmccloy/Bibliography/storage/Y7VJ8YU9/Browman_Goldstein_1989_Articulatory_gestures_as_phonological_units.pdf}
}

@article{WilsonEtAl2004,
  title = {Listening to Speech Activates Motor Areas Involved in Speech Production},
  volume = {7},
  issn = {1097-6256},
  doi = {10.1038/nn1263},
  abstract = {To examine the role of motor areas in speech perception, we carried out a functional magnetic resonance imaging (fMRI) study in which subjects listened passively to monosyllables and produced the same speech sounds. Listening to speech activated bilaterally a superior portion of ventral premotor cortex that largely overlapped a speech production motor area centered just posteriorly on the border of Brodmann areas 4a and 6, which we distinguished from a more ventral speech production area centered in area 4p. Our findings support the view that the motor system is recruited in mapping acoustic inputs to a phonetic code.},
  language = {eng},
  number = {7},
  url = {http://www.nature.com/doifinder/10.1038/nn1263},
  journal = {Nature Neuroscience},
  author = {Wilson, Stephen M. and Saygin, Ay{\c s}e Pinar and Sereno, Martin I. and Iacoboni, Marco},
  month = jul,
  year = {2004},
  pages = {701--702},
  file = {/home/drmccloy/Bibliography/storage/EHC55LTP/WilsonEtAl2004_Listening_to_speech_activates_motor_areas.pdf},
  pmid = {15184903}
}

@book{Duanmu2016,
  address = {Oxford, United Kingdom},
  edition = {First edition},
  series = {Oxford linguistics},
  title = {A Theory of Phonological Features},
  isbn = {978-0-19-966496-2},
  lccn = {P217 .D75 2016},
  url = {http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780199664962.001.0001/acprof-9780199664962},
  publisher = {{Oxford University Press}},
  author = {Duanmu, San},
  month = mar,
  year = {2016},
  file = {/home/drmccloy/Bibliography/storage/3YYHWDA4/Duanmu2016_A_theory_of_phonological_features.pdf},
  doi = {10.1093/acprof:oso/9780199664962.001.0001}
}

@article{Ladefoged2007,
  title = {Articulatory Features for Describing Lexical Distinctions},
  volume = {83},
  issn = {1535-0665},
  doi = {10.1353/lan.2007.0026},
  abstract = {The sounds that distinguish words in the world's languages can be described in terms of properties that are often called (distinctive) features. The best-known attempts to describe sounds in this way are the acoustic features of Jakobson, Fant, and Halle (1952) and the innate cognitive abilities described by the feature theory of Chomsky and Halle (1968). This article provides a more comprehensive answer to the problem of specifying contrasting segments, but one that still leaves some questions open. It also considers the constraints on possible combinations of features, using a development of the notion of a feature hierarchy suggested by Clements (1985).},
  language = {en},
  number = {1},
  urldate = {2017-10-25},
  url = {http://www.jstor.org/stable/4490340},
  journal = {Language},
  author = {Ladefoged, Peter},
  year = {2007},
  pages = {161--180},
  file = {/home/drmccloy/Bibliography/storage/QW6CAW5Q/Ladefoged2007_Articulatory_features_for_describing_lexical.pdf}
}

@article{LibermanMattingly1985,
  title = {The Motor Theory of Speech Perception Revised},
  volume = {21},
  issn = {00100277},
  doi = {10.1016/0010-0277(85)90021-6},
  language = {en},
  number = {1},
  urldate = {2017-10-25},
  url = {http://linkinghub.elsevier.com/retrieve/pii/0010027785900216},
  journal = {Cognition},
  author = {Liberman, Alvin M. and Mattingly, Ignatius G.},
  month = oct,
  year = {1985},
  pages = {1--36},
  file = {/home/drmccloy/Bibliography/storage/R2SKTFR2/LibermanMattingly1985_The_motor_theory_of_speech_perception_revised.pdf},
  pmid = {4075760}
}

@article{Fowler1986,
  title = {An Event Approach to the Study of Speech Perception from a Direct-Realist Perspective},
  volume = {14},
  issn = {1095-8576, 0095-4470},
  abstract = {Proposes an event approach to a theory of speech perception and speech production, focusing on the perception of speech events (i.e., a talker's phonetically structured articulations). In defining a speech event interchangeably from the perspectives of talkers and listeners, the author adopts a "direct realist" perspective: Perception is assumed to recover events in the real world. To do this, perception must be direct and unmediated by cognitive processes of inference or hypothesis testing. Barriers to the theory are outlined and evidence presented to refute them. Support for direct perception of local, short-term events and longer ones is discussed. Attention is also given to the way in which perception of a linguistic message guides a listener's behavior. Differences in the reliability of the information conveyed between direct and indirect perception and the implications for the relation between an utterance and what it signified are examined. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  number = {1},
  journal = {Journal of Phonetics},
  author = {Fowler, Carol A.},
  year = {1986},
  pages = {3--28},
  file = {/home/drmccloy/Bibliography/storage/L6CFIVR2/Fowler1986_An_event_approach_to_the_study_of_speech.pdf}
}

@article{Fowler1991,
  title = {Auditory Perception Is Not Special: {{We}} See the World, We Feel the World, We Hear the World},
  volume = {89},
  issn = {0001-4966},
  shorttitle = {Auditory Perception Is Not Special},
  doi = {10.1121/1.400729},
  abstract = {The literature on "contrast" provides no evidence that durational contrast should occur in the speech and nonsence signals used in research cited by Diehl et al. [J. Acoust. Soc. Am. 89, 2905-2909 (1991)]. Moreover, there is evidence that, in comparable signals, it does not occur. Accordingly, their own account of the collection of findings on rate normalization is not viable. Their comments on my research do not imperil my interpretation of it or challenge my criticism that classification judgments of acoustically analogous speech and nonsense signals do not permit interpretation, by themselves, in terms of underlying auditory-system mechanisms. Their arguments that in auditory perception, uniquely, we hear proximal stimulation, not its physical causal sources, is implausible. Their theoretical perspective generally, I argue, is unrealistic.},
  language = {en},
  number = {6},
  urldate = {2017-10-25},
  url = {http://asa.scitation.org/doi/10.1121/1.400729},
  journal = {The Journal of the Acoustical Society of America},
  author = {Fowler, Carol A.},
  month = jun,
  year = {1991},
  pages = {2910--2915},
  file = {/home/drmccloy/Bibliography/storage/WPULSU8X/Fowler1991_Auditory_perception_is_not_special.pdf},
  pmid = {1918631}
}

@article{Guenther1994,
  title = {A Neural Network Model of Speech Acquisition and Motor Equivalent Speech Production},
  volume = {72},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/BF00206237},
  language = {en},
  number = {1},
  urldate = {2017-10-26},
  url = {http://link.springer.com/10.1007/BF00206237},
  journal = {Biological Cybernetics},
  author = {Guenther, Frank H.},
  month = nov,
  year = {1994},
  pages = {43--53},
  file = {/home/drmccloy/Bibliography/storage/6JI62W3S/Guenther1994_A_neural_network_model_of_speech_acquisition.pdf}
}

@article{TourvilleGuenther2011,
  title = {The {{DIVA}} Model: {{A}} Neural Theory of Speech Acquisition and Production},
  volume = {26},
  issn = {0169-0965, 1464-0732},
  shorttitle = {The {{DIVA}} Model},
  doi = {10.1080/01690960903498424},
  language = {en},
  number = {7},
  urldate = {2017-10-26},
  url = {http://www.tandfonline.com/doi/abs/10.1080/01690960903498424},
  journal = {Language and Cognitive Processes},
  author = {Tourville, Jason A. and Guenther, Frank H.},
  month = aug,
  year = {2011},
  pages = {952--981},
  file = {/home/drmccloy/Bibliography/storage/3RMUY97Z/TourvilleGuenther2011_The_DIVA_model.pdf},
  pmcid = {PMC3650855}
}

@article{Riordan1977,
  title = {Control of Vocal-tract Length in Speech},
  volume = {62},
  issn = {0001-4966},
  doi = {10.1121/1.381595},
  language = {en},
  number = {4},
  urldate = {2017-10-26},
  url = {http://asa.scitation.org/doi/10.1121/1.381595},
  journal = {The Journal of the Acoustical Society of America},
  author = {Riordan, Carol J.},
  month = oct,
  year = {1977},
  pages = {998--1002},
  file = {/home/drmccloy/Bibliography/storage/VDVQVBD6/Riordan1977_Control_of_vocal‐tract_length_in_speech.pdf}
}

@article{LeonardEtAl2015,
  title = {Dynamic Encoding of Speech Sequence Probability in Human Temporal Cortex},
  volume = {35},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.4100-14.2015},
  language = {en},
  number = {18},
  urldate = {2017-11-02},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4100-14.2015},
  journal = {Journal of Neuroscience},
  author = {Leonard, Matthew K. and Bouchard, Kristofer E. and Tang, Claire and Chang, Edward F.},
  month = may,
  year = {2015},
  pages = {7203--7214},
  file = {/home/drmccloy/Bibliography/storage/8PTW3JXN/LeonardEtAl2015_Dynamic_encoding_of_speech_sequence.pdf}
}

@article{Stevens2002,
  title = {Toward a Model for Lexical Access Based on Acoustic Landmarks and Distinctive Features},
  volume = {111},
  issn = {0001-4966},
  doi = {10.1121/1.1458026},
  language = {en},
  number = {4},
  urldate = {2017-11-02},
  url = {http://asa.scitation.org/doi/10.1121/1.1458026},
  journal = {The Journal of the Acoustical Society of America},
  author = {Stevens, Kenneth N.},
  month = apr,
  year = {2002},
  pages = {1872--1891},
  file = {/home/drmccloy/Bibliography/storage/U7G7CUPS/Stevens2002_Toward_a_model_for_lexical_access_based_on.pdf}
}

@incollection{Jones1957,
  address = {London},
  series = {Longman Linguistics Library},
  title = {The History and Meaning of the Term `Phoneme'},
  number = {12},
  booktitle = {Phonetics in {{Linguistics}}: {{A Book}} of {{Readings}}},
  publisher = {{Longman}},
  author = {Jones, Daniel},
  editor = {Jones, W. E. and Laver, John},
  year = {[1973] 1957},
  pages = {187--204},
  file = {/home/drmccloy/Bibliography/storage/B5HXNBV3/Jones1957_The_history_and_meaning_of_the_term_‘phoneme’.pdf}
}

@article{sklearn,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  volume = {12},
  url = {http://www.jmlr.org/papers/v12/pedregosa11a.html},
  journal = {Journal of Machine Learning Research},
  author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  year = {2011},
  pages = {2825--2830}
}

@article{BrombergerHalle1989,
  title = {Why Phonology Is Different},
  volume = {20},
  issn = {00243892, 15309150},
  number = {1},
  url = {http://www.jstor.org/stable/4178613},
  journal = {Linguistic Inquiry},
  author = {Bromberger, Sylvain and Halle, Morris},
  year = {1989},
  pages = {51--70},
  file = {/home/drmccloy/Bibliography/storage/65MCUIIA/BrombergerHalle1989_Why_Phonology_Is_Different.pdf}
}

@article{EvansDavis2015,
  title = {Hierarchical Organization of Auditory and Motor Representations in Speech Perception: {{Evidence}} from Searchlight Similarity Analysis},
  volume = {25},
  issn = {1047-3211, 1460-2199},
  shorttitle = {Hierarchical Organization of Auditory and Motor Representations in Speech Perception},
  doi = {10.1093/cercor/bhv136},
  language = {en},
  number = {12},
  urldate = {2018-01-25},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhv136},
  journal = {Cerebral Cortex},
  author = {Evans, Samuel and Davis, Matthew H.},
  month = dec,
  year = {2015},
  pages = {4772--4788},
  file = {/home/drmccloy/Bibliography/storage/HC3NWETK/EvansDavis2015_Hierarchical_organization_of_auditory_and.pdf}
}

@article{ArsenaultBuchsbaum2015,
  title = {Distributed Neural Representations of Phonological Features during Speech Perception},
  volume = {35},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2454-14.2015},
  language = {en},
  number = {2},
  urldate = {2018-01-29},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2454-14.2015},
  journal = {Journal of Neuroscience},
  author = {Arsenault, Jessica S. and Buchsbaum, Bradley R.},
  month = jan,
  year = {2015},
  pages = {634--642},
  file = {/home/drmccloy/Bibliography/storage/RPXVMBQH/ArsenaultBuchsbaum2015_Distributed_neural_representations_of.pdf}
}

@article{ObleserEtAl2004,
  title = {Magnetic Brain Response Mirrors Extraction of Phonological Features from Spoken Vowels},
  volume = {16},
  issn = {0898-929X},
  doi = {10.1162/089892904322755539},
  abstract = {This study further elucidates determinants of vowel perception in the human auditory cortex. The vowel inventory of a given language can be classified on the basis of phonological features which are closely linked to acoustic properties. A cortical representation of speech sounds based on these phonological features might explain the surprisingly inverse correlation between immense variance in the acoustic signal and high accuracy of speech recognition. We investigated timing and mapping of the N100m elicited by 42 tokens of seven natural German vowels varying along the phonological features tongue height (corresponding to the frequency of the first formant) and place of articulation (corresponding to the frequency of the second and third formants). Auditory evoked fields were recorded using a 148-channel whole-head magnetometer while subjects performed target vowel detection tasks. Source location differences appeared to be driven by place of articulation: Vowels with mutually exclusive place of articulation features, namely, coronal and dorsal elicited separate centers of activation along the posterior-anterior axis. Additionally, the time course of activation as reflected in the N100m peak latency distinguished between vowel categories especially when the spatial distinctiveness of cortical activation was low. In sum, results suggest that both N100m latency and source location as well as their interaction reflect properties of speech stimuli that correspond to abstract phonological features.},
  language = {eng},
  number = {1},
  journal = {Journal of Cognitive Neuroscience},
  author = {Obleser, Jonas and Lahiri, Aditi and Eulitz, Carsten},
  year = {2004 Jan-Feb},
  keywords = {Adult,Brain Mapping,Female,Functional Laterality,Humans,Reaction Time,Speech Perception,Phonetics,Auditory Perception,Auditory Cortex,Evoked Potentials; Auditory,Magnetoencephalography,Reference Values},
  pages = {31--39},
  file = {/home/drmccloy/Bibliography/storage/27LXPP5A/ObleserEtAl2004_Magnetic_brain_response_mirrors_extraction.pdf},
  pmid = {15006034}
}

@misc{scipy1.0.0,
  title = {{{SciPy}}: {{Open}} Source Scientific Tools for {{Python}}},
  url = {http://www.scipy.org/},
  author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu and {et al}},
  year = {2017}
}

@misc{ShaunTheSheep,
  address = {Bristol},
  title = {Shaun the {{Sheep}} (Season 1)},
  publisher = {{Aardman Animations}},
  author = {Starzak, Richard and Sadler, Christopher},
  year = {2007}
}


