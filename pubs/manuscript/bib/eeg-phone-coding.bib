
@misc{phoible2013,
  address = {Munich},
  title = {{PHOIBLE}: {P}honetics Information Base and Lexicon Online},
  url = {http://phoible.org},
  publisher = {{Max Planck Digital Library}},
  editor = {Moran, Steven and McCloy, Daniel R. and Wright, Richard A.},
  year = {2013}
}

@incollection{Wright2004,
  address = {Cambridge},
  title = {A Review of Perceptual Cues and Cue Robustness},
  isbn = {978-0-521-82578-8},
  abstract = {This chapter is an overview of perceptual cues to segmental contrasts. It summarizes previous findings on the type and distribution of cues in the speech signal, and looks at three factors that contribute to the relative perceptual strength of a perceptual contrasts (robustness of encoding): redundancy of cues, the auditory impact of cues, and the resistance of cues to environmental masking. The chapter then relates perceptual robustness to segmental ordering: the most commonly attested segmental sequences, such as alternating consonants and vowels, result in the most robust perceptual encoding of linguistic information, while particularly weak encoding can result from sequences of consonants.},
  booktitle = {Phonetically Based Phonology},
  publisher = {{Cambridge University Press}},
  author = {Wright, Richard A.},
  editor = {Hayes, Bruce and Kirchner, Robert and Steriade, Donca},
  year = {2004},
  pages = {34--57},
  file = {/home/drmccloy/Bibliography/storage/GBEAAKQW/Wright2004_cueRobustness.pdf},
  doi = {10.1017/CBO9780511486401.002}
}

@article{LahiriReetz2010,
  title = {Distinctive Features: {{Phonological}} Underspecification in Representation and Processing},
  volume = {38},
  issn = {0095-4470},
  doi = {10.1016/j.wocn.2010.01.002},
  abstract = {Phonological variation of any sort (determined by speech styles, phrasing, or morphophonological rules) affecting the shapes of words and morphemes are a matter of concern for theories of speech perception and language comprehension. To come to grips with parsing the speech stream, accessing the lexicon and ultimately recognizing words, both representational as well as processing issues must be considered. The central questions in the research presented here are: What is represented in the mental lexicon? How is it represented? How is the speech signal parsed and information mapped onto the mental lexicon? In this paper we will address four issues within the framework of our Featurally Underspecified Lexicon model (FUL): (a) our assumptions concerning distinctive feature organization defined by phonological, perceptual and acoustic constraints; (b) specification of features in the mental lexicon (based on universal and language specific requirements); (c) extracting distinctive features from the signal; (d) mapping features from the signal to the lexicon. We claim that phonological features are extracted from the variable acoustic signal based on broad acoustic properties. A three-way matching algorithm maps these features onto highly abstract phonological mental representations. We provide evidence from synchronic phonological analyses, language change, psycholinguistic and neurolinguistic data.},
  number = {1},
  url = {http://www.sciencedirect.com/science/article/pii/S0095447010000033},
  journal = {Journal of Phonetics},
  author = {Lahiri, Aditi and Reetz, Henning},
  month = jan,
  year = {2010},
  pages = {44--59},
  file = {/home/drmccloy/Bibliography/storage/J3A5QPPQ/Lahiri&Reetz2010_Underspecification.pdf},
  note = {Special issue: Phonetic Bases of Distinctive Features}
}

@book{Hayes2009,
  address = {Oxford, UK},
  title = {Introductory Phonology},
  isbn = {978-1-4051-8411-3},
  language = {English},
  publisher = {{Wiley-Blackwell}},
  author = {Hayes, Bruce P.},
  year = {2009}
}

@incollection{Wright2001,
  address = {San Diego},
  title = {Perceptual Cues in Contrast Maintenance},
  isbn = {978-0-12-361351-6},
  booktitle = {The Role of Speech Perception in Phonology},
  publisher = {{Academic Press}},
  author = {Wright, Richard A.},
  editor = {Hume, Elizabeth V. and Johnson, Keith},
  year = {2001},
  pages = {251--277},
  file = {/home/drmccloy/Bibliography/storage/KC2H3U4E/Wright2001_CueWeighting.pdf}
}

@article{MillerNicely1955,
  title = {An Analysis of Perceptual Confusions among Some {{English}} Consonants},
  volume = {27},
  issn = {00014966},
  doi = {10.1121/1.1907526},
  number = {2},
  urldate = {2013-05-09},
  url = {http://link.aip.org/link/JASMAN/v27/i2/p338/s1\&Agg=doi},
  journal = {The Journal of the Acoustical Society of America},
  author = {Miller, George A. and Nicely, Patricia E.},
  year = {1955},
  pages = {338--352},
  file = {/home/drmccloy/Bibliography/storage/4M8P4C4W/MillerNicely1955_EngConsonantConfusions.pdf;/home/drmccloy/Bibliography/storage/8L3HNFQR/MillerNicely1955_Erratum.pdf}
}

@article{EulitzLahiri2004,
  title = {Neurobiological Evidence for Abstract Phonological Representations in the Mental Lexicon during Speech Recognition},
  volume = {16},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/089892904323057308},
  number = {4},
  urldate = {2013-02-01},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/089892904323057308},
  journal = {Journal of Cognitive Neuroscience},
  author = {Eulitz, Carsten and Lahiri, Aditi},
  month = may,
  year = {2004},
  pages = {577--583},
  file = {/home/drmccloy/Bibliography/storage/F8WUCFTC/Eulitz&Lahiri2004_NeuroEvidenceForPhonology.pdf},
  pmid = {15185677}
}

@incollection{LahiriReetz2002,
  address = {Berlin; New York},
  series = {Phonology and Phonetics},
  title = {Underspecified Recognition},
  isbn = {978-3-11-017086-3},
  number = {4-1},
  booktitle = {Laboratory Phonology 7},
  publisher = {{Mouton de Gruyter}},
  author = {Lahiri, Aditi and Reetz, Henning},
  editor = {Gussenhoven, Carlos and Warner, Natasha},
  year = {2002},
  pages = {637--676},
  file = {/home/drmccloy/Bibliography/storage/TQ52WU7Z/Lahiri&Reetz2002_FUL.pdf}
}

@article{SSP,
  title = {Signal-Space Projection Method for Separating {{MEG}} or {{EEG}} into Components},
  volume = {35},
  issn = {0140-0118, 1741-0444},
  doi = {10.1007/BF02534144},
  language = {en},
  number = {2},
  urldate = {2014-03-21},
  url = {http://link.springer.com/10.1007/BF02534144},
  journal = {Medical \& Biological Engineering \& Computing},
  author = {Uusitalo, M. A. and Ilmoniemi, R. J.},
  month = mar,
  year = {1997},
  pages = {135--140},
  file = {/home/drmccloy/Bibliography/storage/CBTQCDZH/UusitaloIlmoniemi1997_SSP.pdf},
  pmid = {9136207}
}

@article{PowerEtAl2012,
  title = {At What Time Is the Cocktail Party? {{A}} Late Locus of Selective Attention to Natural Speech},
  volume = {35},
  issn = {0953816X},
  shorttitle = {At What Time Is the Cocktail Party?},
  doi = {10.1111/j.1460-9568.2012.08060.x},
  number = {9},
  urldate = {2014-03-10},
  url = {http://doi.wiley.com/10.1111/j.1460-9568.2012.08060.x},
  journal = {European Journal of Neuroscience},
  author = {Power, Alan J. and Foxe, John J. and Forde, Emma-Jane and Reilly, Richard B. and Lalor, Edmund C.},
  month = may,
  year = {2012},
  pages = {1497--1503},
  file = {/home/drmccloy/Bibliography/storage/XFUUQS5K/PowerEtAl2012_LateLocusOfSelectiveAttn.pdf},
  pmid = {22462504}
}

@article{VadenEtAl2010,
  title = {Phonological Repetition-Suppression in Bilateral Superior Temporal Sulci},
  volume = {49},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2009.07.063},
  language = {en},
  number = {1},
  urldate = {2014-03-21},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811909008519},
  journal = {NeuroImage},
  author = {Vaden, Kenneth I. and Muftuler, L. Tugan and Hickok, Gregory},
  month = jan,
  year = {2010},
  pages = {1018--1023},
  file = {/home/drmccloy/Bibliography/storage/SEFMNJSK/VadenetAl2010_PhonologicalRepetitionSuppressionInSTS.pdf},
  pmid = {19651222},
  pmcid = {PMC2764799}
}

@book{ChomskyHalleSPE,
  address = {Cambridge, MA},
  title = {The Sound Pattern of {{English}}},
  isbn = {978-90-00-07517-1},
  publisher = {{MIT Press}},
  author = {Chomsky, Noam and Halle, Morris},
  year = {1968},
  file = {/home/drmccloy/Bibliography/storage/NEGN2QC3/ChomskyHalle1968_SPE.pdf}
}

@article{mnepython,
  title = {{{MEG}} and {{EEG}} Data Analysis with {{MNE}}-{{Python}}},
  volume = {7},
  issn = {1662453X},
  doi = {10.3389/fnins.2013.00267},
  number = {267},
  urldate = {2015-10-05},
  url = {http://journal.frontiersin.org/article/10.3389/fnins.2013.00267/abstract},
  journal = {Frontiers in Neuroscience},
  author = {Gramfort, Alexandre and Luessi, Martin and Larson, Eric D. and Engemann, Denis A. and Strohmeier, Daniel and Brodbeck, Christian and Goj, Roman and Jas, Mainak and Brooks, Teon and Parkkonen, Lauri and H{\"a}m{\"a}l{\"a}inen, Matti S.},
  year = {2013},
  pages = {1--13},
  file = {/home/drmccloy/Bibliography/storage/VQ3XUFX4/GramfortEtAl2013_mnePython.pdf}
}

@article{MesgaraniEtAl2014,
  title = {Phonetic Feature Encoding in Human Superior Temporal Gyrus},
  volume = {343},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1245994},
  language = {en},
  number = {6174},
  urldate = {2015-11-15},
  url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1245994},
  journal = {Science},
  author = {Mesgarani, Nima and Cheung, Connie and Johnson, Keith and Chang, Edward F.},
  month = feb,
  year = {2014},
  pages = {1006--1010},
  file = {/home/drmccloy/Bibliography/storage/D98AKC4A/MesgaraniEtAl2014_Supplement.pdf;/home/drmccloy/Bibliography/storage/RN6CH3VS/MesgaraniEtAl2014_PhonemeHumanECOG.pdf}
}

@article{SarelaValpola2005,
  title = {Denoising Source Separation},
  volume = {6},
  issn = {1533-7928},
  url = {http://www.jmlr.org/papers/v6/sarela05a.html},
  journal = {Journal of Machine Learning Research},
  author = {S{\"a}rel{\"a}, Jaakko and Valpola, Harri},
  year = {2005},
  pages = {233--272},
  file = {/home/drmccloy/Bibliography/storage/9EC99VUG/SarelaValpola2005_DSS.pdf}
}

@article{deCheveigneSimon2008,
  title = {Denoising Based on Spatial Filtering},
  volume = {171},
  issn = {01650270},
  doi = {10.1016/j.jneumeth.2008.03.015},
  language = {en},
  number = {2},
  urldate = {2016-04-12},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0165027008002008},
  journal = {Journal of Neuroscience Methods},
  author = {{de Cheveign{\'e}}, Alain and Simon, Jonathan Z.},
  month = jun,
  year = {2008},
  pages = {331--339},
  file = {/home/drmccloy/Bibliography/storage/GPFUIVZX/deCheveigneSimon2008_DSS.pdf}
}

@book{JakobsonFantHalle1952,
  address = {Cambridge},
  title = {Preliminaries to Speech Analysis: {{The}} Distinctive Features and Their Correlates},
  shorttitle = {Preliminaries to Speech Analysis},
  publisher = {{MIT Press}},
  author = {Jakobson, Roman and Fant, C. Gunnar M. and Halle, Morris},
  year = {1952}
}

@article{HasegawaJohnsonEtAl2016-UnderresourcedASR,
  title = {{{ASR}} for Under-Resourced Languages from Probabilistic Transcription},
  volume = {25},
  issn = {2329-9290, 2329-9304},
  doi = {10.1109/TASLP.2016.2621659},
  number = {1},
  url = {http://ieeexplore.ieee.org/document/7707303/},
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  author = {Hasegawa-Johnson, Mark and Jyothi, Preethi and McCloy, Daniel R. and Mirbagheri, Majid and {di Liberto}, Giovanni and Das, Amit and Ekin, Bradley and Liu, Chunxi and Manohar, Vimal and Tang, Hao and Lalor, Edmund C. and Chen, Nancy and Hager, Paul and Kekona, Tyler and Sloan, Rose and Lee, Adrian K. C.},
  month = jan,
  year = {2017},
  pages = {50--63},
  file = {/home/drmccloy/Bibliography/storage/SJKX5ZWQ/Hasegawa-JohnsonEtAl2016_ASR_for_under-resourced_languages_from_probabilistic.pdf}
}

@article{MielkeHume2006,
  address = {Oxford},
  edition = {2},
  title = {Distinctive Features},
  isbn = {978-0-08-044854-1},
  language = {en},
  urldate = {2016-07-07},
  url = {http://linkinghub.elsevier.com/retrieve/pii/B0080448542000365},
  journal = {Encyclopedia of Language \& Linguistics},
  publisher = {{Elsevier}},
  author = {Mielke, Jeff and Hume, Elizabeth V.},
  editor = {Brown, Keith},
  year = {2006},
  pages = {723--731},
  file = {/home/drmccloy/Bibliography/storage/WNC5WWMV/MielkeHume2006_Distinctive_Features.pdf}
}

@article{RobertsEtAl2014,
  title = {Asymmetric Processing of Durational Differences - Electrophysiological Investigations in {{Bengali}}},
  volume = {58},
  issn = {1873-3514},
  doi = {10.1016/j.neuropsychologia.2014.03.015},
  abstract = {Duration is used contrastively in many languages to distinguish word meaning (e.g. in Bengali, [pata] 'leaf' vs. [pat:a] 'whereabouts'). While there is a large body of research on other contrasts in speech perception (e.g. vowel contrasts and consonantal place features), little work has been done on how durational information is used in speech processing. In non-linguistic studies of low-level processing, such as visual and non-linguistic acoustic pop-out tasks, an asymmetry is found where additional information is more readily detected than missing information. In this study, event-related potentials were recorded during two cross-modal auditory-visual semantic priming studies, where nonword mispronunciations of spoken prime words were created by changing the duration of a medial consonant (real word [dana] 'seed'$>$nonword [dan:a]). N400 amplitudes showed an opposite asymmetric pattern of results, where increases in consonantal duration were tolerated and led to priming of the visual target, but decreases in consonantal duration were not accepted. This asymmetrical pattern of acceptability is attributed to the fact that a longer consonant includes all essential information for the recognition of the original word with a short medial consonant (a possible default category) and any additional information can be ignored. However, when a consonant is shortened, it lacks the required durational information to activate the word with the original long consonant.},
  language = {eng},
  journal = {Neuropsychologia},
  author = {Roberts, Adam C. and Kotzor, Sandra and Wetterlin, Allison and Lahiri, Aditi},
  month = may,
  year = {2014},
  pages = {88--98},
  file = {/home/drmccloy/Bibliography/storage/JE6BAM3K/RobertsEtAl2014_Asymmetric_processing_of_durational_differences_-.pdf},
  pmid = {24726333}
}

@article{MarkiewiczBohland2016,
  title = {Mapping the Cortical Representation of Speech Sounds in a Syllable Repetition Task},
  volume = {141},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2016.07.023},
  language = {en},
  urldate = {2017-04-20},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811916303317},
  journal = {NeuroImage},
  author = {Markiewicz, Christopher J. and Bohland, Jason W.},
  month = nov,
  year = {2016},
  pages = {174--190},
  file = {/home/drmccloy/Bibliography/storage/7DDZT2XG/MarkiewiczBohland2016_Mapping_the_cortical_representation_of_speech_sounds_in_a.pdf}
}

@article{KriegeskorteEtAl2008,
  title = {Representational Similarity Analysis \textendash{} Connecting the Branches of Systems Neuroscience},
  volume = {2},
  issn = {1662-5137},
  doi = {10.3389/neuro.06.004.2008},
  abstract = {A FUNDAMENTAL CHALLENGE FOR SYSTEMS NEUROSCIENCE IS TO QUANTITATIVELY RELATE ITS THREE MAJOR BRANCHES OF RESEARCH: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging (fMRI). Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., fMRI and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices (RDMs), which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis (RSA), in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing RDMs. We demonstrate RSA by relating representations of visual objects as measured with fMRI in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities. The RDMs are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of RSA, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
  url = {http://journal.frontiersin.org/article/10.3389/neuro.06.004.2008/abstract},
  journal = {Frontiers in Systems Neuroscience},
  author = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter},
  year = {2008},
  pages = {4},
  file = {/home/drmccloy/Bibliography/storage/ITAH59TA/KriegeskorteEtAl2008_Representational_similarity_analysis_–_connecting_the_branches_of_systems.pdf},
  pmid = {19104670},
  pmcid = {PMC2605405}
}

@article{BarJosephEtAl2001,
  title = {Fast Optimal Leaf Ordering for Hierarchical Clustering},
  volume = {17},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/17.suppl_1.S22},
  abstract = {We present the first practical algorithm for the optimal linear leaf ordering of trees that are generated by hierarchical clustering. Hierarchical clustering has been extensively used to analyze gene expression data, and we show how optimal leaf ordering can reveal biological structure that is not observed with an existing heuristic ordering method. For a tree with n leaves, there are 2(n-1) linear orderings consistent with the structure of the tree. Our optimal leaf ordering algorithm runs in time O(n(4)), and we present further improvements that make the running time of our algorithm practical.},
  language = {en},
  number = {Suppl 1},
  urldate = {2017-09-05},
  url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/17.suppl_1.S22},
  journal = {Bioinformatics},
  author = {Bar-Joseph, Z. and Gifford, D. K. and Jaakkola, T. S.},
  month = jun,
  year = {2001},
  pages = {S22--S29},
  file = {/home/drmccloy/Bibliography/storage/DD7D687X/Bar-JosephEtAl2001_Fast_optimal_leaf_ordering_for_hierarchical_clustering.pdf},
  pmid = {11472989}
}

@article{BrowmanGoldstein1992,
  title = {Articulatory Phonology: {{An}} Overview},
  volume = {49},
  issn = {0031-8388},
  shorttitle = {Articulatory Phonology},
  doi = {10.1159/000261913},
  abstract = {An overview of the basic ideas of articulatory phonology is presented, along with selected examples of phonological patterning for which the approach seems to provide a particularly insightful account. In articulatory phonology, the basic units of phonological contrast are gestures, which are also abstract characterizations of articulatory events, each with an intrinsic time or duration. Utterances are modeled as organized patterns (constellations) of gestures, in which gestural units may overlap in time. The phonological structures defined in this way provide a set of articulatorily based natural classes. Moreover, the patterns of overlapping organization can be used to specify important aspects of the phonological structure of particular languages, and to account, in a coherent and general way, for a variety of different types of phonological variation. Such variation includes allophonic variation and fluent speech alternations, as well as 'coarticulation' and speech errors. Finally, it is suggested that the gestural approach clarifies our understanding of phonological development, by positing that prelinguistic units of action are harnessed into (gestural) phonological structures through differentiation and coordination.},
  language = {en},
  number = {3-4},
  urldate = {2017-10-16},
  url = {http://www.karger.com/doi/10.1159/000261913},
  journal = {Phonetica},
  author = {Browman, Catherine P. and Goldstein, Louis},
  year = {1992},
  pages = {155--180},
  file = {/home/drmccloy/Bibliography/storage/IJJDFMRK/Browman_Goldstein_1992_Articulatory_phonology.pdf},
  pmid = {1488456}
}

@article{BrowmanGoldstein1989,
  title = {Articulatory Gestures as Phonological Units},
  volume = {6},
  issn = {0952-6757, 1469-8188},
  doi = {10.1017/S0952675700001019},
  language = {en},
  number = {02},
  urldate = {2017-10-16},
  url = {http://www.journals.cambridge.org/abstract_S0952675700001019},
  journal = {Phonology},
  author = {Browman, Catherine P. and Goldstein, Louis},
  month = aug,
  year = {1989},
  pages = {201--251},
  file = {/home/drmccloy/Bibliography/storage/Y7VJ8YU9/Browman_Goldstein_1989_Articulatory_gestures_as_phonological_units.pdf}
}

@article{LeonardEtAl2015,
  title = {Dynamic Encoding of Speech Sequence Probability in Human Temporal Cortex},
  volume = {35},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.4100-14.2015},
  language = {en},
  number = {18},
  urldate = {2017-11-02},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4100-14.2015},
  journal = {Journal of Neuroscience},
  author = {Leonard, Matthew K. and Bouchard, Kristofer E. and Tang, Claire and Chang, Edward F.},
  month = may,
  year = {2015},
  pages = {7203--7214},
  file = {/home/drmccloy/Bibliography/storage/8PTW3JXN/LeonardEtAl2015_Dynamic_encoding_of_speech_sequence.pdf}
}

@incollection{Jones1957,
  address = {London},
  series = {Longman Linguistics Library},
  title = {The History and Meaning of the Term `Phoneme'},
  number = {12},
  booktitle = {Phonetics in {{Linguistics}}: {{A Book}} of {{Readings}}},
  publisher = {{Longman}},
  author = {Jones, Daniel},
  editor = {Jones, W. E. and Laver, John},
  year = {1957},
  pages = {187--204},
  file = {/home/drmccloy/Bibliography/storage/B5HXNBV3/Jones1957_The_history_and_meaning_of_the_term_‘phoneme’.pdf},
  note = {date\_of\_collection: 1973}
}

@article{sklearn,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  volume = {12},
  url = {http://www.jmlr.org/papers/v12/pedregosa11a.html},
  journal = {Journal of Machine Learning Research},
  author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  year = {2011},
  pages = {2825--2830}
}

@article{BrombergerHalle1989,
  title = {Why Phonology Is Different},
  volume = {20},
  issn = {00243892, 15309150},
  number = {1},
  url = {http://www.jstor.org/stable/4178613},
  journal = {Linguistic Inquiry},
  author = {Bromberger, Sylvain and Halle, Morris},
  year = {1989},
  pages = {51--70},
  file = {/home/drmccloy/Bibliography/storage/65MCUIIA/BrombergerHalle1989_Why_Phonology_Is_Different.pdf}
}

@article{EvansDavis2015,
  title = {Hierarchical Organization of Auditory and Motor Representations in Speech Perception: {{Evidence}} from Searchlight Similarity Analysis},
  volume = {25},
  issn = {1047-3211, 1460-2199},
  shorttitle = {Hierarchical Organization of Auditory and Motor Representations in Speech Perception},
  doi = {10.1093/cercor/bhv136},
  language = {en},
  number = {12},
  urldate = {2018-01-25},
  url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhv136},
  journal = {Cerebral Cortex},
  author = {Evans, Samuel and Davis, Matthew H.},
  month = dec,
  year = {2015},
  pages = {4772--4788},
  file = {/home/drmccloy/Bibliography/storage/HC3NWETK/EvansDavis2015_Hierarchical_organization_of_auditory_and.pdf}
}

@article{ArsenaultBuchsbaum2015,
  title = {Distributed Neural Representations of Phonological Features during Speech Perception},
  volume = {35},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2454-14.2015},
  language = {en},
  number = {2},
  urldate = {2018-01-29},
  url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2454-14.2015},
  journal = {Journal of Neuroscience},
  author = {Arsenault, Jessica S. and Buchsbaum, Bradley R.},
  month = jan,
  year = {2015},
  pages = {634--642},
  file = {/home/drmccloy/Bibliography/storage/RPXVMBQH/ArsenaultBuchsbaum2015_Distributed_neural_representations_of.pdf}
}

@article{ObleserEtAl2004,
  title = {Magnetic Brain Response Mirrors Extraction of Phonological Features from Spoken Vowels},
  volume = {16},
  issn = {0898-929X},
  doi = {10.1162/089892904322755539},
  abstract = {This study further elucidates determinants of vowel perception in the human auditory cortex. The vowel inventory of a given language can be classified on the basis of phonological features which are closely linked to acoustic properties. A cortical representation of speech sounds based on these phonological features might explain the surprisingly inverse correlation between immense variance in the acoustic signal and high accuracy of speech recognition. We investigated timing and mapping of the N100m elicited by 42 tokens of seven natural German vowels varying along the phonological features tongue height (corresponding to the frequency of the first formant) and place of articulation (corresponding to the frequency of the second and third formants). Auditory evoked fields were recorded using a 148-channel whole-head magnetometer while subjects performed target vowel detection tasks. Source location differences appeared to be driven by place of articulation: Vowels with mutually exclusive place of articulation features, namely, coronal and dorsal elicited separate centers of activation along the posterior-anterior axis. Additionally, the time course of activation as reflected in the N100m peak latency distinguished between vowel categories especially when the spatial distinctiveness of cortical activation was low. In sum, results suggest that both N100m latency and source location as well as their interaction reflect properties of speech stimuli that correspond to abstract phonological features.},
  language = {eng},
  number = {1},
  journal = {Journal of Cognitive Neuroscience},
  author = {Obleser, Jonas and Lahiri, Aditi and Eulitz, Carsten},
  year = {2004 Jan-Feb},
  keywords = {Adult,Brain Mapping,Female,Functional Laterality,Humans,Reaction Time,Speech Perception,Phonetics,Auditory Perception,Auditory Cortex,Evoked Potentials; Auditory,Magnetoencephalography,Reference Values},
  pages = {31--39},
  file = {/home/drmccloy/Bibliography/storage/27LXPP5A/ObleserEtAl2004_Magnetic_brain_response_mirrors_extraction.pdf},
  pmid = {15006034}
}

@misc{scipy1.0.0,
  title = {{{SciPy}}: {{Open}} Source Scientific Tools for {{Python}}},
  url = {http://www.scipy.org/},
  author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu and {et al}},
  year = {2017}
}

@book{ShaunTheSheep,
  address = {Bristol},
  title = {Shaun the {{Sheep}} (Season 1)},
  publisher = {{Aardman Animations}},
  author = {Starzak, Richard and Sadler, Christopher},
  year = {2007}
}
